{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "file = 'data/data.txt'\n",
    "\n",
    "EOS = '\\n'\n",
    "\n",
    "sentences = LineSentence(file)\n",
    "\n",
    "docs = [ws + [EOS] for ws in sentences]\n",
    "\n",
    "dic = Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Dictionary の内容を JSON で保存\n",
    "with open('dict.json', 'w', encoding = 'utf8') as f:\n",
    "    ds = [{'index': k, 'word': v} for k, v in dic.iteritems()]\n",
    "    json.dump(ds, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Embedding, Dense\n",
    "\n",
    "window_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(dic), 64, input_length = window_size))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(len(dic), activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(model.input_shape)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(ws, size):\n",
    "    for i in range(len(ws) - size + 1):\n",
    "        yield tuple(ws[i:i + size])\n",
    "\n",
    "dw = [t for d in docs for t in split(d, window_size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot = lambda cs: to_categorical(dic.doc2idx([cs]), len(dic))[0]\n",
    "\n",
    "data = np.array([dic.doc2idx(i[0:-1]) for i in dw])\n",
    "labels = np.array([one_hot(i[-1]) for i in dw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "hist = model.fit(data, labels, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rnn-sample.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def predict_next_word(ws):\n",
    "    r = model.predict(np.array([dic.doc2idx(ws)]))\n",
    "    return dic[np.random.choice(len(r[0]), p = r[0])]\n",
    "\n",
    "def generate(fst_word, maxlen = 50):\n",
    "    fs = random.choice([d for d in dw if d[0] == fst_word])\n",
    "    \n",
    "    res = list(fs[0:-1])\n",
    "    \n",
    "    for _ in range(maxlen):\n",
    "        ws = res[-window_size:]\n",
    "\n",
    "        nw = predict_next_word(ws)\n",
    "        \n",
    "        if nw == EOS:\n",
    "            break\n",
    "\n",
    "        res += [nw]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    print( ''.join(generate('その')) )\n",
    "    print('----')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
