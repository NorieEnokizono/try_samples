{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "actions = {'up': (0, -1), 'down': (0, 1), 'left': (-1, 0), 'right': (1, 0)}\n",
    "\n",
    "def attribute(grid, state):\n",
    "    return grid[state[1]][state[0]]\n",
    "\n",
    "def calc_reward(grid, state, reward = -0.04):\n",
    "    r = attribute(grid, state)\n",
    "    \n",
    "    if r is 1:\n",
    "        return (1, True)\n",
    "    elif r is -1:\n",
    "       return (-1, True)\n",
    "    else:\n",
    "        return (reward, False)\n",
    "\n",
    "def policy(state):\n",
    "    return np.random.choice(list(actions.keys()))\n",
    "\n",
    "def move(grid, state, act):\n",
    "    if attribute(grid, state) is not 0:\n",
    "        raise Exception('end')\n",
    "\n",
    "    x, y = actions[act]\n",
    "    next_state = (state[0] + x, state[1] + y)\n",
    "    \n",
    "    if next_state[0] < 0 or next_state[0] >= len(grid[0]) or next_state[1] < 0 or next_state[1] >= len(grid):\n",
    "        return state\n",
    "\n",
    "    if attribute(grid, next_state) is 9:\n",
    "        return state\n",
    "        \n",
    "    return next_state\n",
    "\n",
    "def transit(grid, state, act, p = 0.8):\n",
    "    return {a: (move(grid, state, a), p if act == a else (1 - p) / (len(actions) - 1)) for a in actions}\n",
    "\n",
    "def step(grid, state, act, p = 0.8):\n",
    "    probs = transit(grid, state, act, p)\n",
    "    \n",
    "    cs = list(zip(*probs.values()))\n",
    "    \n",
    "    next_state = cs[0][np.random.choice(range(len(cs[0])), p = cs[1])]\n",
    "    \n",
    "    return (next_state,) + calc_reward(grid, next_state)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1 = [\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 9, 0, -1],\n",
    "    [0, 0, 0, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    state = (0, 0)\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        act = policy(state)\n",
    "        next_state, reward, done = step(grid1, state, act)\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    print(f'state: {state}, reward: {total_reward}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_plan(grid, gamma = 0.9, threshold = 0.0001, p = 0.8):\n",
    "    states = [(x, y) for x in range(len(grid[0])) for y in range(len(grid))]\n",
    "    \n",
    "    v = {s: 0 for s in states}\n",
    "    \n",
    "    calc_value = lambda s, a: sum([\n",
    "        prob * (calc_reward(grid, next_state)[0] + gamma * v[next_state]) \n",
    "        for next_state, prob in transit(grid, s, a, p).values()\n",
    "    ])\n",
    "    \n",
    "    while True:\n",
    "        delta = 0\n",
    "        \n",
    "        for s in v:\n",
    "            if attribute(grid, s) != 0:\n",
    "                continue\n",
    "            \n",
    "            max_reward = max([calc_value(s, a) for a in actions])\n",
    "\n",
    "            delta = max(delta, abs(max_reward - v[s]))\n",
    "            \n",
    "            v[s] = max_reward\n",
    "        \n",
    "        if delta < threshold:\n",
    "            break\n",
    "    \n",
    "    print(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_plan(grid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_plan(grid, gamma = 0.9, threshold = 0.0001, p = 0.8):\n",
    "    states = [(x, y) for x in range(len(grid[0])) for y in range(len(grid))]\n",
    "    \n",
    "    policies = {s: {a: 1 / len(actions) for a in actions} for s in states}\n",
    "\n",
    "    calc_value = lambda s, a, v, aprob = 1.0: sum([\n",
    "        aprob * prob * (calc_reward(grid, next_state)[0] + gamma * v[next_state]) \n",
    "        for next_state, prob in transit(grid, s, a, p).values()\n",
    "    ])\n",
    "\n",
    "    take_action = lambda ap: max(ap, key = ap.get)\n",
    "    \n",
    "    def estimate():\n",
    "        v = {s: 0 for s in states}\n",
    "    \n",
    "        while True:\n",
    "            delta = 0\n",
    "        \n",
    "            for s in v:\n",
    "                if attribute(grid, s) != 0:\n",
    "                    continue\n",
    "\n",
    "                max_reward = max([calc_value(s, a, v, policies[s][a]) for a in actions])\n",
    "\n",
    "                delta = max(delta, abs(max_reward - v[s]))\n",
    "\n",
    "                v[s] = max_reward\n",
    "        \n",
    "            if delta < threshold:\n",
    "                break\n",
    "        return v\n",
    "\n",
    "\n",
    "    while True:\n",
    "        unupdated = True\n",
    "    \n",
    "        V = estimate()\n",
    "        \n",
    "        for s in states:\n",
    "            if attribute(grid, s) != 0:\n",
    "                continue\n",
    "\n",
    "            policy_action = take_action(policies[s])\n",
    "    \n",
    "            rewards = {a: calc_value(s, a, V) for a in policies[s]}\n",
    "        \n",
    "            best_action = take_action(rewards)\n",
    "            \n",
    "            for a in policies[s]:\n",
    "                policies[s][a] = 1 if a == best_action else 0\n",
    "            \n",
    "            if policy_action != best_action:\n",
    "                unupdated = False\n",
    "        \n",
    "        if unupdated:\n",
    "            break\n",
    "   \n",
    "    print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_plan(grid1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
